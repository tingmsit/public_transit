---
title: "Final Code MGMT 6203 Team 16"
output: html_document
date: "2023-07-20"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Instruction**: 
Download the "RideAustin_Weather" csv file from the link location "Data Files too large html links" and save that under "Data" folder. The code file is to be downloaded into "Code" folder. 

Download the "vehicles" csv file from the link location "Data Files too large html links" and save that under "Data" folder. The code file is to be downloaded into "Code" folder. 

Dowload all other Data files from Github into data folder



```{r packages}
rm(list = ls())
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(plotly)
library(lubridate)
library(chron)
set.seed(123)
```

### Calculating CO2 of rideshare data
```{r co2}
rides <- read.csv("RideAustin_Weather.csv")
vehicles <- read.csv("vehicles.csv")
#View(vehicles)
#View(rides) #distance traveled is in meters

vinfo <- vehicles[, c('year', 'make', 'model', 'barrels08', 'barrelsA08', 'city08', 'cityA08', 'co2', 'co2A')]
#CO2 grams per mile, barrels in barrels per mile, city miles per gallon

vinfo2 <- vinfo %>% group_by(year, make, model) %>% sample_n(1)
#Due to multiple lines in the vehicles data set take a random sample of one type of year, make, model and assign it to the ride

df <- left_join(rides, vinfo2, by=c('year', 'make', 'model'))
#Vehicle data has multiple types of cars with same year, make, and model

numrows <- nrow(df)
numNA <- sum(is.na(df$co2))

perNa <- numNA/numrows * 100
#43% of data had NA values

#Due to us having such a large sample size comfortable estimating volume based solely on rows with car data
df2 <- df %>% drop_na(co2)

df2$calcco2 = ifelse(df2$co2 > 0 & df2$co2A > 0 , mean(c(df2$co2,df2$co2A)),
                      ifelse(df2$co2 > df2$co2A, df2$co2, df2$co2A))

CO2emmited = df2$distance_travelled*0.000621371 * df2$calcco2 #convert meters to miles
TotalCo2samp <- sum(subset(CO2emmited, CO2emmited >0))*0.001 #Ignore hybrid car rides convert to kilograms

totCO2 = TotalCo2samp / length(df2$distance_travelled)*length(rides$distance_travelled) #Volume adjust back to CO2 Estimate

print("Total CO2 Emmited is")
print(totCO2)
print("km")
```
```{r read_data}
rideshare <- read.csv('RideAustin_Weather.csv')
capmetro_dow_hour <- read.csv("CapMetro ridership all by latlong dow hour.csv")
```
```{r exploratory}
#rideshare <- read.csv("RideAustin_Weather.csv")
#capmetro_dow_hour <- read.csv("CapMetro ridership all by latlong dow hour.csv")

summary(rideshare)

rideshare_filter <- rideshare %>%
  filter(distance_travelled < 15000)
rideshare_filter$dist_km <- rideshare_filter$distance_travelled/1000
# Obtain day of week
rideshare_filter$dow <- wday(mdy(rideshare_filter$Date), label = TRUE)
# Obtain month
rideshare_filter$mo <- month(mdy(rideshare_filter$Date), label = TRUE)

# Convert start and end time text into datetime object

rideshare_filter$start_ts <- as.POSIXct(rideshare_filter$started_on, format = "%m/%d/%Y %H:%M")
rideshare_filter$end_ts <- as.POSIXct(rideshare_filter$completed_on, format = "%m/%d/%Y %H:%M")

# Obtain hour of the day
rideshare_filter$hour <- rideshare_filter$start_ts %>%
  hour()

# Calculate time traveled
rideshare_filter$ts_travel <- difftime(rideshare_filter$end_ts,
  rideshare_filter$start_ts, units = "mins")

# Limit travel time to be less than 120 minutes
rideshare_ts <- rideshare_filter %>%
  filter(ts_travel > 0 & ts_travel < 120)




dist_travel <- ggplot(rideshare_filter, aes(dist_km)) + geom_histogram(binwidth = 1) +
  labs(title = "Distance Traveled Distribution for ride share trips",
    x = "Distance Traveled (km)", y = "# of Trips")

dist_travel_cum <- ggplot(rideshare_filter, aes(dist_km)) + stat_ecdf(geom = "step") +
  labs(title = "Cumlative % for ride share trips", x = "Distance Traveled (km)",
    y = "% to total")

grid.arrange(dist_travel, dist_travel_cum, ncol = 2)


dist_ts <- ggplot(rideshare_ts, aes(ts_travel)) + stat_ecdf(geom = "step") +
  labs(title = "Time Traveled by ride share trips", x = "Time (mins)",
    y = "% to total")

day_count <- ggplot(rideshare_filter, aes(x = dow)) + geom_bar() +
  labs(title = "Ride share trips distribution by Day", x = "Day of Week",
    y = "# Trip")


weather_fog <- day_count + facet_grid(vars(Fog)) + labs(title = "Day distribution conditioned on Fog",
  x = "Day", y = "# Trip")

weather_thunder <- day_count + facet_grid(vars(Thunder)) + labs(title = "Day distribution conditioned on Thunder",
  x = "Day", y = "# Trip")

# month_count <- ggplot(rideshare_filter, aes(x = mo)) +
# geom_bar() month_count


hour_count <- ggplot(rideshare_filter, aes(x = hour)) + geom_bar() +
  labs(title = "Time of Day", x = "Hour", y = "# of Trip")


grid.arrange(hour_count, dist_ts, day_count, ncol = 2, nrow = 2)

grid.arrange(weather_fog, weather_thunder, ncol = 1, nrow = 2)

# rideshare_filter$start_loc <- paste('(',
# as.character(rideshare_filter$start_location_long) ,',',
# as.character(rideshare_filter$start_location_lat),')')
# rideshare_filter$end_loc <- paste('(',
# as.character(rideshare_filter$end_location_long) ,',',
# as.character(rideshare_filter$end_location_lat),')')
# rideshare_filter$from_to <- paste('(',
# as.character(rideshare_filter$start_loc) ,',',
# as.character(rideshare_filter$end_loc),')')

# Create a new dataset group by hour and dow and assign new buckets for regression analysis

rideshare_group <- rideshare_filter %>%
  group_by(dow, hour) %>%
  summarize(vol = n())

rideshare_group$wkd <- ifelse((rideshare_group$dow == "Sun" |
  rideshare_group$dow == "Sat"), "weekend", "weekday")
rideshare_group$hr_cat <- ifelse((rideshare_group$hour >= 22 |
  rideshare_group$hour < 6), "darkout", ifelse((rideshare_group$hour >=
  6 & rideshare_group$hour < 10), "rush_hour", ifelse((rideshare_group$hour >=
  10 & rideshare_group$hour < 17), "work_hour", "evening")))


daytime_lm <- lm(vol ~ hr_cat + wkd, data = rideshare_group)
summary(daytime_lm)
plot(daytime_lm)

# Preparing data for K-S Test

fog_count <- rideshare_filter %>%
  group_by(Fog) %>%
  summarise(n = n()) %>%
  filter(Fog == 1)
thunder_count <- rideshare_filter %>%
  group_by(Thunder) %>%
  summarise(n = n()) %>%
  filter(Thunder == 1)

no_fog <- rideshare_filter %>%
  filter(Fog == 0) %>%
  sample_n(size = fog_count$n) %>%
  group_by(dow) %>%
  summarize(n = n())
fog <- rideshare_filter %>%
  filter(Fog == 1) %>%
  group_by(dow) %>%
  summarize(n = n())
ks.test(no_fog$n, fog$n)

no_thunder <- rideshare_filter %>%
  filter(Thunder == 0) %>%
  sample_n(size = thunder_count$n) %>%
  group_by(dow) %>%
  summarize(n = n())
thunder <- rideshare_filter %>%
  filter(Thunder == 1) %>%
  group_by(dow) %>%
  summarize(n = n())
ks.test(no_thunder$n, thunder$n)

# capmetro exploratory

bus_dow <- capmetro_dow_hour %>%
  group_by(start_time_dayofwk) %>%
  summarize(ride = sum(rides_on), n = n()) %>%
  mutate(dow = wday(start_time_dayofwk, label = TRUE))

dow_ride <- ggplot(bus_dow, aes(dow, ride)) + geom_bar(stat = "identity") +
  labs(title = "Ride Volume by Day", x = "Day of Week", y = "# Passengers")

dow_count <- ggplot(bus_dow, aes(dow, n)) + geom_bar(stat = "identity") +
  labs(title = "Est. Bus Count by Day", x = "Day of Week", y = "Est. Bus Count")

grid.arrange(dow_ride, dow_count, ncol = 2)


bus_hr <- capmetro_dow_hour %>%
  group_by(start_time_hour) %>%
  summarize(ride = sum(rides_on), n = n()) %>% mutate

hr_ride <- ggplot(bus_hr, aes(start_time_hour, ride)) + geom_bar(stat = "identity") +
  labs(title = "Ride Volume by Hour", x = "Hour", y = "# Passengers")

hr_count <- ggplot(bus_hr, aes(start_time_hour, n)) + geom_bar(stat = "identity") +
  labs(title = "Est. Bus Count by hour", x = "Hour", y = "Est. Bus Count")

grid.arrange(hr_ride, hr_count, ncol = 2)

bus_hr_dow <- capmetro_dow_hour %>%
  group_by(start_time_dayofwk, start_time_hour) %>%
  summarize(ride = sum(rides_on), n = n()) %>%   mutate(dow = wday(start_time_dayofwk, label = TRUE))

bus_share <- merge(bus_hr_dow, rideshare_group, by.x = c('start_time_hour', 'dow'), by.y = c('hour', 'dow'))
# lm_bus_share <- lm(vol ~ ride + hr_cat, data=bus_share)
# summary(lm_bus_share)


# Testing if rides volume is correlated to bus ride
cor.test(bus_share$vol, bus_share$ride, method='pearson')
```

```{r rideshare vs public transportation}
austin_data <- read.csv("RideAustin_Weather with dow and hour.csv")
capmetro_stops <- read.csv("Austin capmetro stops.csv")
capmetro_rides <- read.csv("CapMetro ridership all by latlong.csv")
capmetro_dow_hour <- read.csv("CapMetro ridership all by latlong dow hour.csv")

#Shrink dataset to relevant columns
rideshare = subset(austin_data, select = c(completed_on, started_on, distance_travelled, end_location_lat, end_location_long, start_location_lat, start_location_long, started_dow, started_hour, make, model, year))

#Filter rideshare data for rides within general range of public transportation
rideshares_in_range <- rideshare %>%
  filter(start_location_lat > 30 & start_location_lat < 30.6
         & start_location_long > -97.8 & start_location_long < -97.5
         & end_location_lat > 30 & end_location_lat < 30.6
         & end_location_long > -97.8 & end_location_long < -97.5)

#Filter CapMetro data for rides within general range of public transportation (data sometimes include other cities)
capmetro_in_range <- capmetro_rides %>%
  filter(veh_lat_rnd > 30 & veh_lat_rnd < 30.6
         & veh_long_rnd > -97.8 & veh_long_rnd < -97.5)

summary(rideshares_in_range)
summary(capmetro_in_range)

#Total number of rideshare trips
totrides = count(rideshares_in_range)
totrides
totpassgrs = totrides*1.4 #Avg number of people per rideshare trip (https://www.proquest.com/openview/e72295e320ad0316f0bfbe8a1102bdd7/1?cbl=36781&pq-origsite=gscholar&parentSessionId=X1bHyMnX3sD0okvHEK2hrOW8xWLrsmS3KLUF61sWfg8%3D)
totpassgrs

#Get total and pct of rideshare trips by lat/long pair
rides_per_latlong <- rideshares_in_range %>% group_by(start_location_lat, start_location_long) %>% tally(name="rides")
rides_per_latlong$passgrs <- rides_per_latlong$rides*1.4
rides_per_latlong$pctrideshare <- rides_per_latlong$rides / as.integer(totrides)


#Total riders on public transportation
totpubtrans <- sum(capmetro_in_range$rides_on)
totpubtrans

#Add pct ridership by lat/long for public transportation
capmetro_in_range$pctpubtrans <- capmetro_in_range$rides_on/totpubtrans

#Join rideshare and public transportation ridership by lat/long
merged_data = merge(x = rides_per_latlong, y = capmetro_in_range, by.x = c("start_location_lat", "start_location_long"), by.y = c("veh_lat_rnd", "veh_long_rnd"), all = TRUE, replace.na = 0)
rownames(merged_data) = NULL


linreg_passgrs <- lm(passgrs~rides_on, merged_data)
summary(linreg_passgrs)
#As expected, highly significant relationship between number of passengers on public transportation and doing ridesharing at a particular location (See adj. R2: about 35% of the variance in rideshare volume across the city is just due to location)

linreg_pctrides <- lm(pctrideshare~pctpubtrans, merged_data)
summary(linreg_pctrides)
#And same result when we translate this to percent of rides/passengers (Adj. R2 = 35%).

#Still, ~65% of the variation between ridership distributions is not simply due to location. Can we improve on this model by adding other factors?


#Adding month and day of week to regression analysis:
#Filter for correct range
capmetro_in_range_dow_hour <- capmetro_dow_hour %>%
  filter(veh_lat_rnd > 30 & veh_lat_rnd < 30.6
         & veh_long_rnd > -97.8 & veh_long_rnd < -97.5)

#Get total and pct of rideshare trips by lat/long pair, day of week, and hour
rides_per_latlong_dow_hour <- rideshares_in_range %>% group_by(start_location_lat, start_location_long, started_dow, started_hour) %>% tally(name="rides")
rides_per_latlong_dow_hour$passgrs <- rides_per_latlong_dow_hour$rides*1.4
rides_per_latlong_dow_hour$pctrideshare <- rides_per_latlong_dow_hour$rides / as.integer(totrides)

#Total riders on public transportation
totpubtrans <- sum(capmetro_in_range_dow_hour$rides_on)
totpubtrans

#Add pct ridership by lat/long for public transportation
capmetro_in_range_dow_hour$pctpubtrans <- capmetro_in_range_dow_hour$rides_on/totpubtrans

#Join rideshare and public transportation ridership by lat/long, month, and day of week
merged_data_dow_hour = merge(x = rides_per_latlong_dow_hour, y = capmetro_in_range_dow_hour, by.x = c("start_location_lat", "start_location_long", "started_dow", "started_hour"), by.y = c("veh_lat_rnd", "veh_long_rnd", "start_time_dayofwk", "start_time_hour"), all = TRUE, replace.na = 0)
rownames(merged_data_dow_hour) = NULL

#Create weekday and workhours variables
merged_data_dow_hour$weekday <- ifelse(merged_data_dow_hour$started_dow > 1 & merged_data_dow_hour$started_dow < 7, 1, 0)
merged_data_dow_hour$workhours <- ifelse(merged_data_dow_hour$started_hour > 6 & merged_data_dow_hour$started_hour < 19, 1, 0)

#Convert variables to categorical
merged_data_dow_hour$started_dow <- as.factor(merged_data_dow_hour$started_dow)
merged_data_dow_hour$weekday <- as.factor(merged_data_dow_hour$weekday)
merged_data_dow_hour$started_hour <- as.factor(merged_data_dow_hour$started_hour)
merged_data_dow_hour$workhours <- as.factor(merged_data_dow_hour$workhours)

#Regression with passengers, day of week, and hour of day
linreg_dow_hour <- lm(passgrs~rides_on + weekday + workhours, merged_data_dow_hour)
summary(linreg_dow_hour)
#All three variables are significant, and there is little correlation between ridesharing and public transportation. This suggests that people are more likely to use ridesharing on weekends and on off hours (even though CapMetro offers late night services in some locations)

```
```{r distance calc}
# Euclidean distance function, small area so we ignore curvature of Earth
# https://www.usgs.gov/faqs/how-much-distance-does-a-degree-minute-and-second-cover-your-maps#:~:text=One%2Ddegree%20of%20longitude%20equals,one%20second%20equals%2080%20feet.
euclidean <- function(long1, lat1, long2, lat2) {
  # Convert coordinates to feet
  lat1_ft <- lat1 * 364000 # 364000 feet is in a degree roughly for latitude
  lat2_ft <- lat2 * 364000
  long1_ft <- long1 * 316000 # longitude changes based on latitude, at Austin, TX, a 
  long2_ft <- long2 * 316000 # degree of longitude is about 316000 feet
  
  # Return Euclidean distance: https://www.cuemath.com/euclidean-distance-formula/
  sqrt((long2_ft - long1_ft)^2 + (lat2_ft - lat1_ft)^2)
}

# All Austin bus stop locations with coordinates to calculate average of 3 nearest bus stops to 
# each rideshare on
bus_stops <- read.csv('austin_stops.csv') 

start_mean <- as.numeric(nrow(merged_data_dow_hour))

for (i in 1:nrow(merged_data_dow_hour)) {
  # For each start location, calculate distance from every single bus stop in 
  # the bus stop dataset and then find the nearest distances and find the mean of
  # those, I'm not sure the best way to do it but this calculates the distance
  # using a euclidean function
  start_distance <- euclidean(long1 = merged_data_dow_hour$start_location_long[i],
                              lat1 = merged_data_dow_hour$start_location_lat[i], 
                              long2 = bus_stops$LONGITUDE, 
                              lat2 = bus_stops$LATITUDE)
  
  # Get mean of x nearest distances, we can play around with this
  start_mean[i] <- mean(sort(start_distance)[1:3])#:3])
}

# Add mean distance from x nearest bus stops to data frame to match a distance to  
# nearest bus stop from each rideshare pick-up oordinate
merged_data_dow_hour$start_dist_from_bus <- start_mean

merged_data_dow_hour <- merged_data_dow_hour %>%
  mutate(
    start_lat_bin = case_when(
      start_location_lat >= 30 & start_location_lat < 30.12 ~ '1',
      start_location_lat >= 30.12 & start_location_lat < 30.24 ~ '2',
      start_location_lat >= 30.24 & start_location_lat < 30.36 ~ '3',
      start_location_lat >= 30.36 & start_location_lat < 30.48 ~ '4',
      start_location_lat >= 30.48 & start_location_lat <= 30.6 ~ '5'
    ),
    start_long_bin = case_when(
      start_location_long >= -97.8 & start_location_long < -97.74 ~ 'A',
      start_location_long >= -97.74 & start_location_long < -97.68 ~ 'B',
      start_location_long >= -97.68 & start_location_long < -97.62 ~ 'C',
      start_location_long >= -97.62 & start_location_long < -97.56 ~ 'D',
      start_location_long >= -97.56 & start_location_long <= -97.5 ~ 'E'
    ),
    start_grid_cell = interaction(start_lat_bin, start_long_bin, sep = '-')
  )


linreg_dow_hour <- lm(passgrs ~ rides_on + weekday + workhours + start_dist_from_bus,
                      merged_data_dow_hour)
summary(linreg_dow_hour)

write.csv(merged_data_dow_hour, 'master_data_file.csv')
```
```{r gridregression}
df <- read.csv("RideAustin_Weather.csv")

summary(df)
# Remove distance which are too long, convert meter to km, and create day of week metric
rideshare <- df %>%
  filter(distance_travelled < 15000) %>%
  mutate(dist_km = distance_travelled/1000, dow = wday(mdy(Date),
    label = TRUE))

rideshare$start_ts <- as.POSIXct(rideshare_filter$started_on, format = "%m/%d/%Y %H:%M")
rideshare$end_ts <- as.POSIXct(rideshare_filter$completed_on, format = "%m/%d/%Y %H:%M")
rideshare$ts <- difftime(rideshare$end_ts, rideshare$start_ts,
  units = "mins")

# take out trips that last more than 2 hours
rideshare <- rideshare %>%
  filter(ts > 0 & ts < 120)

rideshare$hour <- rideshare$started_on %>%
  as.POSIXct(format = "%m/%d/%Y %H:%M") %>%
  hour()


rideshare_gp <- rideshare %>%
  group_by(dow, hour) %>%
  summarise(ride_vol = n() * 1.4)


rideshare_gp$wkd_end <- ifelse((rideshare_gp$dow == "Sun" | rideshare_gp$dow ==
  "Sat"), "weekend", "weekday")
rideshare_gp$hr_cat <- ifelse((rideshare_gp$hour < 6), "darkout",
  ifelse((rideshare_gp$hour >= 6 & rideshare_gp$hour < 12),
    "rush_hour", ifelse((rideshare_gp$hour >= 12 & rideshare_gp$hour <
      18), "work_hour", "evening")))

# check significant of day of week and hour of day
summary(lm(ride_vol ~ wkd_end + hr_cat, data = rideshare_gp))

# K-S Test
fog_count <- rideshare %>%
  group_by(Fog) %>%
  summarise(n = n()) %>%
  filter(Fog == 1)
thunder_count <- rideshare %>%
  group_by(Thunder) %>%
  summarise(n = n()) %>%
  filter(Thunder == 1)

set.seed(123)
no_fog <- rideshare %>%
  filter(Fog == 0) %>%
  sample_n(size = fog_count$n) %>%
  group_by(dow) %>%
  summarize(n = n())
fog <- rideshare %>%
  filter(Fog == 1) %>%
  group_by(dow) %>%
  summarize(n = n())
ks.test(no_fog$n, fog$n)

no_thunder <- rideshare %>%
  filter(Thunder == 0) %>%
  sample_n(size = thunder_count$n) %>%
  group_by(dow) %>%
  summarize(n = n())
thunder <- rideshare %>%
  filter(Thunder == 1) %>%
  group_by(dow) %>%
  summarize(n = n())
ks.test(no_thunder$n, thunder$n)

# Bus ride dataset

capmetro <- read.csv("CapMetro ridership all by latlong dow hour.csv")
capmetro$dow <- substr(weekdays(as.Date("2017-01-01") + capmetro$start_time_dayofwk),
  1, 3)
capmetro_gp <- capmetro %>%
  group_by(dow, start_time_hour) %>%
  summarize(bus_vol = sum(rides_on))
capmetro_gp$wkd_end <- ifelse((capmetro_gp$dow == "Sat" | capmetro_gp$dow ==
  "Sun"), "weekend", "weekday")
capmetro_gp$hr_cat <- ifelse((capmetro_gp$start_time_hour < 6),
  "darkout", ifelse((capmetro_gp$start_time_hour >= 6 & capmetro_gp$start_time_hour <
    12), "rush_hour", ifelse((capmetro_gp$start_time_hour >=
    12 & capmetro_gp$start_time_hour < 18), "work_hour",
    "evening")))

# combine bus and rideshare dataset to prepare for regression
final_df <- merge(rideshare_gp, capmetro_gp, by.x = c("wkd_end",
  "hr_cat", "dow", "hour"), by.y = c("wkd_end", "hr_cat", "dow",
  "start_time_hour"))

# Correlation test
cor.test(final_df$bus_vol, final_df$ride_vol)


reg <- lm(ride_vol ~ bus_vol + wkd_end + hr_cat, data = final_df)
summary(reg)

# adding grid to both rideshare and capmetro dataset
grid_map <- read.csv("master_data_file.csv")
grid <- unique(grid_map[, c("start_location_lat", "start_location_long",
                            "start_grid_cell")])

# Note some trips will be dropped as they fall outside the 5x5 grid
rideshare_1 <- merge(rideshare, grid, by = c("start_location_long",
  "start_location_lat"))


rideshare_1_gp <- rideshare_1 %>%
  group_by(dow, hour, start_grid_cell) %>%
  summarise(ride_vol = n() * 1.4)


rideshare_1_gp$wkd_end <- ifelse((rideshare_1_gp$dow == "Sun" |
  rideshare_1_gp$dow == "Sat"), "weekend", "weekday")
rideshare_1_gp$hr_cat <- ifelse((rideshare_1_gp$hour < 6), "darkout",
  ifelse((rideshare_1_gp$hour >= 6 & rideshare_1_gp$hour <
    12), "rush_hour", ifelse((rideshare_1_gp$hour >= 12 &
    rideshare_1_gp$hour < 18), "work_hour", "evening")))

capmetro_1 <- capmetro
capmetro_1 <- merge(capmetro, grid, by.x = c("veh_lat_rnd", "veh_long_rnd"),
  by.y = c("start_location_lat", "start_location_long"))
capmetro_1_gp <- capmetro_1 %>%
  group_by(dow, start_time_hour, start_grid_cell) %>%
  summarize(bus_vol = sum(rides_on))
capmetro_1_gp$wkd_end <- ifelse((capmetro_1_gp$dow == "Sat" |
  capmetro_1_gp$dow == "Sun"), "weekend", "weekday")
capmetro_1_gp$hr_cat <- ifelse((capmetro_1_gp$start_time_hour <
  6), "darkout", ifelse((capmetro_1_gp$start_time_hour >= 6 &
  capmetro_1_gp$start_time_hour < 12), "rush_hour", ifelse((capmetro_1_gp$start_time_hour >=
  12 & capmetro_1_gp$start_time_hour < 18), "work_hour", "evening")))
final_df_1 <- merge(rideshare_1_gp, capmetro_1_gp, by.x = c("wkd_end",
  "hr_cat", "dow", "hour", 'start_grid_cell'), by.y = c("wkd_end", "hr_cat", "dow",
  "start_time_hour", 'start_grid_cell'))

reg_1 <- lm(ride_vol ~ bus_vol + wkd_end + hr_cat + start_grid_cell, data = final_df_1)
summary(reg_1)

```
```{r Co2}
rides <- rideshare_1
vehicles <- read.csv("vehicles.csv")
#View(vehicles)
#View(rides) #distance traveled is in meters

vinfo <- vehicles[, c('year', 'make', 'model','co2', 'co2A')]
#CO2 grams per mile, barrels in barrels per mile, city miles per gallon

vinfo2 <- vinfo %>% group_by(year, make, model) %>% sample_n(1)
#Due to multiple lines in the vehicles data set take a random sample of one type of year, make, model and assign it to the ride

dfco2 <- left_join(rides, vinfo2, by=c('year', 'make', 'model'))
#Vehicle data has multiple types of cars with same year, make, and model

numrows <- nrow(df)
numNA <- sum(is.na(df$co2))

perNa <- numNA/numrows * 100
#43% of data had NA values

#Due to us having such a large sample size comfortable estimating volume based solely on rows with car data
df2 <- dfco2 %>% drop_na(co2)

df2$calcco2 = ifelse(df2$co2 > 0 & df2$co2A > 0 , mean(c(df2$co2,df2$co2A)),
                      ifelse(df2$co2 > df2$co2A, df2$co2, df2$co2A))

CO2emmited = df2$distance_travelled*0.000621371 * df2$calcco2 #convert meters to miles
TotalCo2samp <- sum(subset(CO2emmited, CO2emmited >0))*0.001 #Ignore hybrid car rides convert to kilograms

totCO2 = TotalCo2samp / length(df2$distance_travelled)*length(rides$distance_travelled) #Volume adjust back to CO2 Estimate
print(totCO2)
```