---
title: "Final Code MGMT 6203 Team 16"
output: html_document
date: "2023-07-20"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Instruction**: 
Download the "RideAustin_Weather" csv file from the link location "Data Files too large html links" and save that under the same folder location as the code file. The code file is to be downloaded into "Code" folder. 

Download the "vehicles" csv file from the link location "Data Files too large html links" and save that under the same folder as the code file. The code file is to be downloaded into "Code" folder. 

Dowload all other Data files from Github into data folder



```{r packages}
rm(list = ls())
# install.packages('lubridate')
# install.packages('chron')
# install.packages('gridExtra')

library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(plotly)
library(lubridate)
library(chron)
set.seed(123)
```

### rideshare vs public transport

```{r rideshare vs public transportation}
austin_data <- read.csv("RideAustin_Weather with dow and hour.csv")
capmetro_stops <- read.csv("Austin capmetro stops.csv")
capmetro_rides <- read.csv("CapMetro ridership all by latlong.csv")
capmetro_dow_hour <- read.csv("CapMetro ridership all by latlong dow hour.csv")

#Shrink dataset to relevant columns
rideshare_sub = subset(austin_data, select = c(completed_on, started_on, distance_travelled, end_location_lat, end_location_long, start_location_lat, start_location_long, started_dow, started_hour, make, model, year))

#Filter rideshare data for rides within general range of public transportation
rideshares_in_range <- rideshare_sub %>%
  filter(start_location_lat > 30 & start_location_lat < 30.6
         & start_location_long > -97.8 & start_location_long < -97.5
         & end_location_lat > 30 & end_location_lat < 30.6
         & end_location_long > -97.8 & end_location_long < -97.5)

#Filter CapMetro data for rides within general range of public transportation (data sometimes include other cities)
capmetro_in_range <- capmetro_rides %>%
  filter(veh_lat_rnd > 30 & veh_lat_rnd < 30.6
         & veh_long_rnd > -97.8 & veh_long_rnd < -97.5)

summary(rideshares_in_range)
summary(capmetro_in_range)

#Total number of rideshare trips
totrides = count(rideshares_in_range)
totrides
totpassgrs = totrides*1.4 #Avg number of people per rideshare trip (https://www.proquest.com/openview/e72295e320ad0316f0bfbe8a1102bdd7/1?cbl=36781&pq-origsite=gscholar&parentSessionId=X1bHyMnX3sD0okvHEK2hrOW8xWLrsmS3KLUF61sWfg8%3D)
totpassgrs

#Get total and pct of rideshare trips by lat/long pair
rides_per_latlong <- rideshares_in_range %>% group_by(start_location_lat, start_location_long) %>% tally(name="rides")
rides_per_latlong$passgrs <- rides_per_latlong$rides*1.4
rides_per_latlong$pctrideshare <- rides_per_latlong$rides / as.integer(totrides)


#Total riders on public transportation
totpubtrans <- sum(capmetro_in_range$rides_on)
totpubtrans

#Add pct ridership by lat/long for public transportation
capmetro_in_range$pctpubtrans <- capmetro_in_range$rides_on/totpubtrans

#Join rideshare and public transportation ridership by lat/long
merged_data = merge(x = rides_per_latlong, y = capmetro_in_range, by.x = c("start_location_lat", "start_location_long"), by.y = c("veh_lat_rnd", "veh_long_rnd"), all = TRUE, replace.na = 0)
rownames(merged_data) = NULL


linreg_passgrs <- lm(passgrs~rides_on, merged_data)
summary(linreg_passgrs)
#As expected, highly significant relationship between number of passengers on public transportation and doing ridesharing at a particular location (See adj. R2: about 35% of the variance in rideshare volume across the city is just due to location)

linreg_pctrides <- lm(pctrideshare~pctpubtrans, merged_data)
summary(linreg_pctrides)
#And same result when we translate this to percent of rides/passengers (Adj. R2 = 35%).

#Still, ~65% of the variation between ridership distributions is not simply due to location. Can we improve on this model by adding other factors?


#Adding month and day of week to regression analysis:
#Filter for correct range
capmetro_in_range_dow_hour <- capmetro_dow_hour %>%
  filter(veh_lat_rnd > 30 & veh_lat_rnd < 30.6
         & veh_long_rnd > -97.8 & veh_long_rnd < -97.5)

#Get total and pct of rideshare trips by lat/long pair, day of week, and hour
rides_per_latlong_dow_hour <- rideshares_in_range %>% group_by(start_location_lat, start_location_long, started_dow, started_hour) %>% tally(name="rides")
rides_per_latlong_dow_hour$passgrs <- rides_per_latlong_dow_hour$rides*1.4
rides_per_latlong_dow_hour$pctrideshare <- rides_per_latlong_dow_hour$rides / as.integer(totrides)

#Total riders on public transportation
totpubtrans <- sum(capmetro_in_range_dow_hour$rides_on)
totpubtrans

#Add pct ridership by lat/long for public transportation
capmetro_in_range_dow_hour$pctpubtrans <- capmetro_in_range_dow_hour$rides_on/totpubtrans

#Join rideshare and public transportation ridership by lat/long, month, and day of week
merged_data_dow_hour = merge(x = rides_per_latlong_dow_hour, y = capmetro_in_range_dow_hour, by.x = c("start_location_lat", "start_location_long", "started_dow", "started_hour"), by.y = c("veh_lat_rnd", "veh_long_rnd", "start_time_dayofwk", "start_time_hour"), all = TRUE, replace.na = 0)
rownames(merged_data_dow_hour) = NULL

#Create weekday and workhours variables
merged_data_dow_hour$weekday <- ifelse(merged_data_dow_hour$started_dow > 1 & merged_data_dow_hour$started_dow < 7, 1, 0)
merged_data_dow_hour$workhours <- ifelse(merged_data_dow_hour$started_hour > 6 & merged_data_dow_hour$started_hour < 19, 1, 0)

#Convert variables to categorical
merged_data_dow_hour$started_dow <- as.factor(merged_data_dow_hour$started_dow)
merged_data_dow_hour$weekday <- as.factor(merged_data_dow_hour$weekday)
merged_data_dow_hour$started_hour <- as.factor(merged_data_dow_hour$started_hour)
merged_data_dow_hour$workhours <- as.factor(merged_data_dow_hour$workhours)

#Regression with passengers, day of week, and hour of day
linreg_dow_hour <- lm(passgrs~rides_on + weekday + workhours, merged_data_dow_hour)
summary(linreg_dow_hour)
#All three variables are significant, and there is little correlation between ridesharing and public transportation. This suggests that people are more likely to use ridesharing on weekends and on off hours (even though CapMetro offers late night services in some locations)

```
```{r distance calc}
# Euclidean distance function, small area so we ignore curvature of Earth
# https://www.usgs.gov/faqs/how-much-distance-does-a-degree-minute-and-second-cover-your-maps#:~:text=One%2Ddegree%20of%20longitude%20equals,one%20second%20equals%2080%20feet.
euclidean <- function(long1, lat1, long2, lat2) {
  # Convert coordinates to feet
  lat1_ft <- lat1 * 364000 # 364000 feet is in a degree roughly for latitude
  lat2_ft <- lat2 * 364000
  long1_ft <- long1 * 316000 # longitude changes based on latitude, at Austin, TX, a 
  long2_ft <- long2 * 316000 # degree of longitude is about 316000 feet
  
  # Return Euclidean distance: https://www.cuemath.com/euclidean-distance-formula/
  sqrt((long2_ft - long1_ft)^2 + (lat2_ft - lat1_ft)^2)
}

# All Austin bus stop locations with coordinates to calculate average of 3 nearest bus stops to 
# each rideshare on
bus_stops <- read.csv('austin_stops.csv') 

start_mean <- as.numeric(nrow(merged_data_dow_hour))

for (i in 1:nrow(merged_data_dow_hour)) {
  # For each start location, calculate distance from every single bus stop in 
  # the bus stop dataset and then find the nearest distances and find the mean of
  # those, I'm not sure the best way to do it but this calculates the distance
  # using a euclidean function
  start_distance <- euclidean(long1 = merged_data_dow_hour$start_location_long[i],
                              lat1 = merged_data_dow_hour$start_location_lat[i], 
                              long2 = bus_stops$LONGITUDE, 
                              lat2 = bus_stops$LATITUDE)
  
  # Get mean of x nearest distances, we can play around with this
  start_mean[i] <- mean(sort(start_distance)[1:3])#:3])
}

# Add mean distance from x nearest bus stops to data frame to match a distance to  
# nearest bus stop from each rideshare pick-up oordinate
merged_data_dow_hour$start_dist_from_bus <- start_mean

merged_data_dow_hour <- merged_data_dow_hour %>%
  mutate(
    start_lat_bin = case_when(
      start_location_lat >= 30 & start_location_lat < 30.12 ~ '1',
      start_location_lat >= 30.12 & start_location_lat < 30.24 ~ '2',
      start_location_lat >= 30.24 & start_location_lat < 30.36 ~ '3',
      start_location_lat >= 30.36 & start_location_lat < 30.48 ~ '4',
      start_location_lat >= 30.48 & start_location_lat <= 30.6 ~ '5'
    ),
    start_long_bin = case_when(
      start_location_long >= -97.8 & start_location_long < -97.74 ~ 'A',
      start_location_long >= -97.74 & start_location_long < -97.68 ~ 'B',
      start_location_long >= -97.68 & start_location_long < -97.62 ~ 'C',
      start_location_long >= -97.62 & start_location_long < -97.56 ~ 'D',
      start_location_long >= -97.56 & start_location_long <= -97.5 ~ 'E'
    ),
    start_grid_cell = interaction(start_lat_bin, start_long_bin, sep = '-')
  )


linreg_dow_hour <- lm(passgrs ~ rides_on + weekday + workhours + start_dist_from_bus,
                      merged_data_dow_hour)
summary(linreg_dow_hour)

write.csv(merged_data_dow_hour, 'master_data_file.csv')
```

# Exploratory Analysis
```{r exploratory+grid}

rideshare <- read.csv('RideAustin_Weather.csv')
capmetro <- read.csv("CapMetro ridership all by latlong dow hour.csv")

summary(rideshare)
# Remove distance which are too long, convert meter to km,
# and create day of week metric
rideshare <- rideshare %>%
  filter(distance_travelled < 15000) %>%
  mutate(dist_km = distance_travelled/1000, dow = wday(mdy(Date),
    label = TRUE))


rideshare$start_ts <- as.POSIXct(rideshare$started_on, format="%m/%d/%Y %H:%M")
rideshare$end_ts <- as.POSIXct(rideshare$completed_on, format="%m/%d/%Y %H:%M")
rideshare$ts <- difftime(rideshare$end_ts, rideshare$start_ts,
                         units = "mins")

# take out trips that last more than 2 hours
rideshare <- rideshare %>%
  filter(ts > 0 & ts < 120)

rideshare$hour <- rideshare$started_on %>%
  as.POSIXct(format="%m/%d/%Y %H:%M") %>%
  hour()


# exploring ride volume pattern by travel distance
dist_travel <- ggplot(rideshare, aes(dist_km)) + geom_histogram(binwidth = 1) +
  labs(title = "Distance Traveled Distribution for ride share trips",
    x = "Distance Traveled (km)", y = "# of Trips")

dist_travel_cum <- ggplot(rideshare, aes(dist_km)) + stat_ecdf(geom = "step") +
  labs(title = "Cumlative % for ride share trips", x = "Distance Traveled (km)",
    y = "% to total")

grid.arrange(dist_travel, dist_travel_cum, ncol = 2)

# exploring ride volume pattern by travel time
dist_ts <- ggplot(rideshare, aes(ts)) + stat_ecdf(geom = "step") +
  labs(title = "Time Traveled by ride share trips", x = "Time (mins)",
    y = "% to total")

day_count <- ggplot(rideshare, aes(x = dow)) + geom_bar() + labs(title = "Ride share trips distribution by Day",
  x = "Day of Week", y = "# Trip")


weather_fog <- day_count + facet_grid(vars(Fog)) + labs(title = "Day distribution conditioned on Fog",
  x = "Day", y = "# Trip")

weather_thunder <- day_count + facet_grid(vars(Thunder)) + labs(title = "Day distribution conditioned on Thunder",
  x = "Day", y = "# Trip")


hour_count <- ggplot(rideshare, aes(x = hour)) + geom_bar() +
  labs(title = "Time of Day", x = "Hour", y = "# of Trip")


grid.arrange(hour_count, dist_ts, day_count, ncol = 2, nrow = 2)

grid.arrange(weather_fog, weather_thunder, ncol = 1, nrow = 2)


# Create a new dataset group by hour and dow and assign new
# buckets for regression analysis

rideshare_gp <- rideshare %>%
  group_by(dow, hour) %>%
  summarise(ride_vol = n() * 1.4)


rideshare_gp$wkd_end <- ifelse((rideshare_gp$dow == "Sun" | rideshare_gp$dow ==
  "Sat"), "weekend", "weekday")
rideshare_gp$hr_cat <- ifelse((rideshare_gp$hour < 6), "darkout",
  ifelse((rideshare_gp$hour >= 6 & rideshare_gp$hour < 12),
    "rush_hour", ifelse((rideshare_gp$hour >= 12 & rideshare_gp$hour <
      18), "work_hour", "evening")))


# check significant of day of week and hour of day
summary(lm(ride_vol ~ wkd_end + hr_cat, data = rideshare_gp))

# Preparing data for K-S Test

fog_count <- rideshare %>%
  group_by(Fog) %>%
  summarise(n = n()) %>%
  filter(Fog == 1)
thunder_count <- rideshare %>%
  group_by(Thunder) %>%
  summarise(n = n()) %>%
  filter(Thunder == 1)

set.seed(123)
no_fog <- rideshare %>%
  filter(Fog == 0) %>%
  sample_n(size = fog_count$n) %>%
  group_by(dow) %>%
  summarize(n = n())
fog <- rideshare %>%
  filter(Fog == 1) %>%
  group_by(dow) %>%
  summarize(n = n())
ks.test(no_fog$n, fog$n)

no_thunder <- rideshare %>%
  filter(Thunder == 0) %>%
  sample_n(size = thunder_count$n) %>%
  group_by(dow) %>%
  summarize(n = n())
thunder <- rideshare %>%
  filter(Thunder == 1) %>%
  group_by(dow) %>%
  summarize(n = n())
ks.test(no_thunder$n, thunder$n)

# capmetro exploratory


bus_hr <- capmetro %>%
  group_by(start_time_hour) %>%
  summarize(ride = sum(rides_on), n = n())

# explore bus ride pattern driven by hour of the day

hr_ride <- ggplot(bus_hr, aes(start_time_hour, ride)) + geom_bar(stat = "identity") +
  labs(title = "Ride Volume by Hour", x = "Hour", y = "# Passengers")

hr_count <- ggplot(bus_hr, aes(start_time_hour, n)) + geom_bar(stat = "identity") +
  labs(title = "Est. Bus Count by hour", x = "Hour", y = "Est. Bus Count")

grid.arrange(hr_ride, hr_count, ncol = 2)

# explore bus ride pattern driven by day of week
bus_hr_dow <- capmetro %>%
  group_by(start_time_dayofwk, start_time_hour) %>%
  summarize(ride = sum(rides_on), n = n()) %>%
  mutate(dow = wday(start_time_dayofwk, label = TRUE))

bus_dow <- capmetro %>%
  group_by(start_time_dayofwk) %>%
  summarize(ride = sum(rides_on), n = n()) %>%
  mutate(dow = wday(start_time_dayofwk, label = TRUE))

dow_ride <- ggplot(bus_dow, aes(dow, ride)) + geom_bar(stat = "identity") +
  labs(title = "Ride Volume by Day", x = "Day of Week", y = "# Passengers")

dow_count <- ggplot(bus_dow, aes(dow, n)) + geom_bar(stat = "identity") +
  labs(title = "Est. Bus Count by Day", x = "Day of Week",
    y = "Est. Bus Count")

grid.arrange(dow_ride, dow_count, ncol = 2)

# modifying dataset to mimic rideshare datase to prepare
# for merge

capmetro$dow <- substr(weekdays(as.Date("2017-01-01") + capmetro$start_time_dayofwk),
  1, 3)
capmetro_gp <- capmetro %>%
  group_by(dow, start_time_hour) %>%
  summarize(bus_vol = sum(rides_on))
capmetro_gp$wkd_end <- ifelse((capmetro_gp$dow == "Sat" | capmetro_gp$dow ==
  "Sun"), "weekend", "weekday")
capmetro_gp$hr_cat <- ifelse((capmetro_gp$start_time_hour < 6),
  "darkout", ifelse((capmetro_gp$start_time_hour >= 6 & capmetro_gp$start_time_hour <
    12), "rush_hour", ifelse((capmetro_gp$start_time_hour >=
    12 & capmetro_gp$start_time_hour < 18), "work_hour",
    "evening")))


# combine bus and rideshare dataset to prepare for
# regression
final_df <- merge(rideshare_gp, capmetro_gp, by.x = c("wkd_end",
  "hr_cat", "dow", "hour"), by.y = c("wkd_end", "hr_cat", "dow",
  "start_time_hour"))

# Correlation test
cor.test(final_df$bus_vol, final_df$ride_vol)

# Regression to check significant on the independent
# variables

reg <- lm(ride_vol ~ bus_vol + wkd_end + hr_cat, data = final_df)
summary(reg)


# adding grid to both rideshare and capmetro dataset
grid_map <- read.csv("master_data_file.csv")
grid <- unique(grid_map[, c("start_location_lat", "start_location_long",
  "start_grid_cell")])

# Note some trips will be dropped as they fall outside the
# 5x5 grid
rideshare_1 <- merge(rideshare, grid, by = c("start_location_long",
  "start_location_lat"))


rideshare_1_gp <- rideshare_1 %>%
  group_by(dow, hour, start_grid_cell) %>%
  summarise(ride_vol = n() * 1.4)


rideshare_1_gp$wkd_end <- ifelse((rideshare_1_gp$dow == "Sun" |
  rideshare_1_gp$dow == "Sat"), "weekend", "weekday")
rideshare_1_gp$hr_cat <- ifelse((rideshare_1_gp$hour < 6), "darkout",
  ifelse((rideshare_1_gp$hour >= 6 & rideshare_1_gp$hour <
    12), "rush_hour", ifelse((rideshare_1_gp$hour >= 12 &
    rideshare_1_gp$hour < 18), "work_hour", "evening")))

capmetro_1 <- capmetro
capmetro_1 <- merge(capmetro, grid, by.x = c("veh_lat_rnd", "veh_long_rnd"),
  by.y = c("start_location_lat", "start_location_long"))
capmetro_1_gp <- capmetro_1 %>%
  group_by(dow, start_time_hour, start_grid_cell) %>%
  summarize(bus_vol = sum(rides_on))
capmetro_1_gp$wkd_end <- ifelse((capmetro_1_gp$dow == "Sat" |
  capmetro_1_gp$dow == "Sun"), "weekend", "weekday")
capmetro_1_gp$hr_cat <- ifelse((capmetro_1_gp$start_time_hour <
  6), "darkout", ifelse((capmetro_1_gp$start_time_hour >= 6 &
  capmetro_1_gp$start_time_hour < 12), "rush_hour", ifelse((capmetro_1_gp$start_time_hour >=
  12 & capmetro_1_gp$start_time_hour < 18), "work_hour", "evening")))
final_df_1 <- merge(rideshare_1_gp, capmetro_1_gp, by.x = c("wkd_end",
  "hr_cat", "dow", "hour", "start_grid_cell"), by.y = c("wkd_end",
  "hr_cat", "dow", "start_time_hour", "start_grid_cell"))

reg_1 <- lm(ride_vol ~ bus_vol + wkd_end + hr_cat + start_grid_cell,
  data = final_df_1)
summary(reg_1)

```

```{r Co2}
rides <- rideshare_1
vehicles <- read.csv("vehicles.csv")
#View(vehicles)
#View(rides) #distance traveled is in meters

vinfo <- vehicles[, c('year', 'make', 'model','co2', 'co2A')]
#CO2 grams per mile, barrels in barrels per mile, city miles per gallon

vinfo2 <- vinfo %>% group_by(year, make, model) %>% sample_n(1)
#Due to multiple lines in the vehicles data set take a random sample of one type of year, make, model and assign it to the ride

dfco2 <- left_join(rides, vinfo2, by=c('year', 'make', 'model'))
#Vehicle data has multiple types of cars with same year, make, and model

numrows <- nrow(df)
numNA <- sum(is.na(df$co2))

perNa <- numNA/numrows * 100
#43% of data had NA values

#Due to us having such a large sample size comfortable estimating volume based solely on rows with car data
df2 <- dfco2 %>% drop_na(co2)

df2$calcco2 = ifelse(df2$co2 > 0 & df2$co2A > 0 , mean(c(df2$co2,df2$co2A)),
                      ifelse(df2$co2 > df2$co2A, df2$co2, df2$co2A))

CO2emmited = df2$distance_travelled*0.000621371 * df2$calcco2 #convert meters to miles
TotalCo2samp <- sum(subset(CO2emmited, CO2emmited >0))*0.001 #Ignore hybrid car rides convert to kilograms

totCO2 = TotalCo2samp / length(df2$distance_travelled)*length(rides$distance_travelled) #Volume adjust back to CO2 Estimate
print(totCO2)
```

```{r USCensus}
#This new file has a few new variables from the US Census American Community Survey (ACS).
#The census data goes down to the level of census tracts, which are approximately neighborhood-sized, and I was able to map the latitude/longitude onto those census tracts.
#For us, the important variables were median household income (median_hincome) and population density (ppsm = people per square mile).
#A final variable is the number of different combinations of locations, days, and hours that a rideshare was requested in a given census tract, represented by the "n_var" variable.
#This variable is a little tricky to interpret, but I think it speaks to the fact that some areas of the city have not only higher demand for transportation, but more varied demand, and those areas tend to have stronger public transportation use.
#When I grouped the data by census tract, then, instead oflat/long pair, it gave us a useful amount of aggregation - more specific than a 5x5 grid, but less granular than lat/long.


master_data <- read.csv("master_data_file_with_census_vars.csv")

master_data$passgrs_per_ppsm <- master_data$passgrs/master_data$ppsm

master_grp <- master_data %>%
  group_by(tract, ppsm, median_hincome) %>%
  summarise(start_dist_from_bus = mean(start_dist_from_bus, na.rm=TRUE), passgrs = sum(passgrs, na.rm=TRUE), rides_on = sum(rides_on, na.rm=TRUE), passgrs_per_ppsm = sum(passgrs, na.rm=TRUE)/mean(ppsm, na.rm=TRUE), n_var = n())   #n_var represents variety in use of ridesharing (locations, times of day, and days of week)

linreg_dow_hour_grp <- lm(rides_on~passgrs + ppsm + median_hincome + n_var, master_grp)
summary(linreg_dow_hour_grp)

#The new model is a better predictor of public transportation use, with R2 value of 0.525.
#Yes, rideshares and public transportation are positively correlated, but the model is still useful in predicting which locations would be best suited for expanding public transportation options.
#Basically, this model says that we should look for areas that have high rideshare demand, that are densely populated, with lower median income, and with more varied rideshare use (i.e., at many hours of day, days of week, and different lat/long points).


#We can use this model to suggest the best location(s) for new expansion:
#This gives us a list of locations with no current public transportation use, and predicts the number of public transportation rides that could be gained per six-month period if we expanded into that area.
possible_loc <- master_grp %>% filter(rides_on == 0)
possible_loc$pred <- ifelse(predict(linreg_dow_hour_grp, possible_loc)<0, 0, predict(linreg_dow_hour_grp, possible_loc))

#This model would suggest that the best candidate is a neighborhood on the north boundary of CapMetro's service area, an area called Round Rock.
#I think it's a reasonable suggestion because it's continguous to the current (as of Jan. 2017) service area, and it's right next several college campuses, like Texas A&M and Austin Comm. College.
#In fact, in March 2017, right after the period that this dataset represents, CapMetro did decide to expand into this area with four new routes, which is a nice confirmation of our analysis.
#Here's the article: https://cbsaustin.com/news/local/round-rock-to-get-capmetro-bus-service-in-august
```